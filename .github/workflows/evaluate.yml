name: Model Evaluation

on:
  workflow_run:
    workflows: ["Tests and Linting"]  
    types:
      - completed

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run evaluation script
        run: |
          python evaluate.py > metrics.txt

      - name: Check accuracy threshold
        run: |
          acc=$(grep "Test accuracy:" metrics.txt | awk '{print $3}')
          threshold=0.70
          echo "ðŸ“Š Accuracy: $acc / Threshold: $threshold"
          if (( $(echo "$acc < $threshold" | bc -l) )); then
            echo "âŒ Accuracy below threshold"
            exit 1
          else
            echo "âœ… Accuracy OK"
          fi

      - name: Upload metrics
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-metrics
          path: metrics.txt
